{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Встановлення та імпорт необхідних модулів"
      ],
      "metadata": {
        "id": "sH1r_Zu2fM_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNeLhgwxVY1K",
        "outputId": "c4f66039-a78d-41ee-f795-e0355ce9e359"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3nI2YuNqVQM",
        "outputId": "2cdd06e3-c6dc-43ef-d6c0-239cf2bfa987"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "EZTkj-PUIL9Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.base import clone\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Аргументація вибору базових моделей на основі Дерев Рішень\n",
        "\n",
        "У двох минулих роботах з опрацювання навичок регресії та класифікації даних за допомогою методів машинного навчання було розглянуто два датасети, на яких примітивна модель Desicion Tree Regressor&Classifier показала досить очікувані результати з високими можливостями прогнозування результаів кінцевого таргету, але з частковим перенавчанням.\n",
        "\n",
        "Тому в цій роботі нашою задачею буде спроба регулювання аріхетектури задля підвищення результативності її роботи за допомогою методів ансамблювання та ансамблю моделей. Очікується підвищення точності прогнозування за рахунок комбінування прогнозів від кількох моделей.\n",
        "\n",
        "#### **Будуть розглянуті:**\n",
        "* **Decision Tree (Дерево рішень)**: Наглядний і легко інтерпретований метод машинного навчання, який використовується як для класифікації, так і для регресії. Метод працює шляхом розбиття датасету на менші підмножини на основі запитань, що ставляться про атрибути даних, ефективно створюючи деревоподібну структуру з \"листками\" (рішеннями) і \"гілками\" (правилами розділення).\n",
        "\n",
        "* **Bagging (Bootstrap Aggregating)**: Метод, що полягає в генерації кількох підмножин даних шляхом випадкового відбору з повтореннями з оригінального набору даних. Незалежні моделі навчаються на цих підмножинах паралельно. Прогнози від всіх моделей агрегуються (наприклад, шляхом голосування для класифікації або усереднення для регресії) для отримання кінцевого прогнозу. Bagging допомагає зменшити варіативність і запобігти перенавчанню.\n",
        "\n",
        "* **Random Forest**: Це спеціалізований тип Bagging, де використовуються дерева рішень як базові моделі. Крім випадкового відбору даних, Random Forest також вводить випадковість у вибір ознак при розщепленні вузлів дерева, що дозволяє додатково зменшити кореляцію між деревами. Це забезпечує ще більше зниження варіативності і покращує загальну точність моделі порівняно з простим Bagging.\n",
        "\n",
        "* **ExtraTrees** (Extremely Randomized Trees, Екстремально випадкові дерева): Ансамблевий алгоритм машинного навчання, що використовує множину дерев рішень для завдань класифікації та регресії. Він подібний до алгоритму Random Forest, але відрізняється за двома ключовими параметрами, які роблять його \"екстремально випадковим\":\n",
        "  1. Вибір розділових точок: При створенні кожного розділу в дереві, замість пошуку найкращої точки розділу серед усіх можливих для кожної ознаки (як це робиться в Random Forest), в ExtraTrees випадковим чином вибирається декілька точок розділу для кожної ознаки, а потім з цих точок вибирається та, що дає найкращий розділ. Цей процес дозволяє знизити варіативність моделі за рахунок більшої випадковості.\n",
        "  2. Вибір ознак: Подібно до Random Forest, ExtraTrees використовує підмножину ознак для кожного розділу, але процес вибору ознак ще більше випадковий.\n",
        "\n",
        "* **CatBoost**: Високопродуктивна бібліотека для градієнтного бустингу оптимізована для роботи з категорійними даними. Вона автоматично перетворює категорійні ознаки на числові, зменшуючи ризик перенавчання через техніки як обмеження глибини дерев, регуляризація, та випадкові перестановки.\n",
        "\n",
        "* **Gradient Boosting**: Метод машинного навчання, що використовується для задач регресії, класифікації та інших, який побудований на принципі послідовного покращення прогнозів за допомогою невеликих дерев рішень. Кожне наступне дерево намагається виправити помилки попередніх, застосовуючи градієнтний спуск для мінімізації втрат (функції втрат). Таким чином, модель поступово, крок за кроком, покращує свою точність.\n",
        "\n",
        "* **LightGBM**: Є реалізацією алгоритму градієнтного бустингу, розробленою компанією Microsoft. Це ефективний та швидкий алгоритм, який використовує техніку побудови дерева на основі гістограм, що дозволяє йому обробляти великі об'єми даних з меншими вимогами до пам'яті та вищою швидкістю навчання порівняно з іншими алгоритмами бустингу, такими як XGBoost або GradientBoostingClassifier з sklearn.\n",
        "\n",
        "* **Stacking (Стекінг)**: Використовує концепцію \"моделей моделей\". У цьому підході кілька різних моделей навчаються незалежно, а їх прогнози використовуються як вхідні дані для \"мета-моделі\", яка намагається вивчити, як найкраще комбінувати прогнози базових моделей для отримання кінцевого прогнозу. Stacking спрямований на зловживання різноманітності базових моделей для покращення прогнозів, вивчаючи, яким чином помилки одних моделей можуть компенсуватися іншими.\n",
        "\n"
      ],
      "metadata": {
        "id": "fy5RVc2afUvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Регресія\n"
      ],
      "metadata": {
        "id": "hW5F4aOZIOKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "y = pd.DataFrame(housing.target, columns=[\"Target\"])"
      ],
      "metadata": {
        "id": "pWfsyQjOIPrX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_RyVVQ6NIW-n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2exl7UN4Im4q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення y_train і y_test з pandas DataFrame або Series у одновимірні NumPy масиви\n",
        "y_train_raveled = y_train.values.flatten()\n",
        "y_test_raveled = y_test.values.flatten()"
      ],
      "metadata": {
        "id": "G8JgvbzURHX3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Функція тренування та оцінки моделі регресії"
      ],
      "metadata": {
        "id": "hBuW95heijtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate(model, X_train, X_test, y_train, y_test):\n",
        "  # Навчання моделі\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Передбачення значень для тестового набору\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  # Оцінка моделі\n",
        "  mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "  mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "  mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "  mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "  r2_train = r2_score(y_train, y_train_pred)\n",
        "  r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "  # Виведення результатів\n",
        "  print(\"MSE Train:\", mse_train, \"\\nMSE Test:\", mse_test)\n",
        "  print(\"MAE Train:\", mae_train, \"\\nMAE Test:\", mae_test)\n",
        "  print(\"R² Train:\", r2_train, \"\\nR² Test:\", r2_test)"
      ],
      "metadata": {
        "id": "HNeha7EZRMlT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Класична модель дерева рішень DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "CBpzxdkRJrps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення моделі дерева рішень\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(X_train, y_train)\n",
        "\n",
        "# Передбачення значень для тестового набору\n",
        "y_train_pred = tree_reg.predict(X_train)\n",
        "y_test_pred = tree_reg.predict(X_test)\n",
        "\n",
        "# Оцінка моделі\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Виведення результатів\n",
        "print(\"MSE Train:\", mse_train, \"\\nMSE Test:\", mse_test)\n",
        "print(\"MAE Train:\", mae_train, \"\\nMAE Test:\", mae_test)\n",
        "print(\"R² Train:\", r2_train, \"\\nR² Test:\", r2_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PaMRLtMIqRK",
        "outputId": "db37e239-43fd-4d6c-92f3-64d97fedc448"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 1.0357621381535573e-31 \n",
            "MSE Test: 0.49396854311945243\n",
            "MAE Train: 4.5936553441370335e-17 \n",
            "MAE Test: 0.45390448401162786\n",
            "R² Train: 1.0 \n",
            "R² Test: 0.6230424613065773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging на основі моделі дерева рішень"
      ],
      "metadata": {
        "id": "V0SV5T6jJy-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення базової моделі\n",
        "base_model = DecisionTreeRegressor(max_depth=5)\n",
        "\n",
        "# Створення ансамблевої моделі з використанням Bagging\n",
        "bagging_model = BaggingRegressor(estimator=base_model, n_estimators=5, random_state=42, max_samples=0.1, max_features=0.1)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(bagging_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Py4RAw4Jxq7",
        "outputId": "255901b3-a42a-49f8-cdd3-d07d2dec9f9a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.8858253576574003 \n",
            "MSE Test: 0.8787613534194602\n",
            "MAE Train: 0.7315623118413944 \n",
            "MAE Test: 0.7290898003732517\n",
            "R² Train: 0.33734306121609803 \n",
            "R² Test: 0.3293991662060235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Після налаштування гіперпараметрів"
      ],
      "metadata": {
        "id": "l7o3hkSppvQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення базової моделі\n",
        "base_model = DecisionTreeRegressor(max_depth=10, min_samples_leaf=8, min_samples_split=8)\n",
        "\n",
        "# Створення ансамблевої моделі з використанням Bagging\n",
        "bagging_model = BaggingRegressor(estimator=base_model, n_estimators=50, random_state=42, max_samples=0.7, max_features=0.9)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(bagging_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNB2FsjOLKNQ",
        "outputId": "6ca07a2a-8ec0-4a11-b50c-2f6e8c3c81ad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.20453934529076426 \n",
            "MSE Test: 0.2689382984057167\n",
            "MAE Train: 0.31109319203032865 \n",
            "MAE Test: 0.351503073825164\n",
            "R² Train: 0.8469908145667893 \n",
            "R² Test: 0.7947676619502859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Використання ExtraTreesRegressor як базової моделі\n"
      ],
      "metadata": {
        "id": "t-UvPogNi6J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення базової моделі з використанням ExtraTreesRegressor\n",
        "base_model = ExtraTreesRegressor(n_estimators=20, random_state=42)\n",
        "\n",
        "# Створення ансамблевої моделі з використанням Bagging\n",
        "bagging_model = BaggingRegressor(estimator=base_model, n_estimators=20, random_state=42, max_samples=0.8, max_features=0.8)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(bagging_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFWMgUigN4Sk",
        "outputId": "c02cf6cc-1dae-4886-e712-25133a552bd7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.04846362489023224 \n",
            "MSE Test: 0.22266256599784096\n",
            "MAE Train: 0.14556562971021064 \n",
            "MAE Test: 0.3175205285428779\n",
            "R² Train: 0.9637459494306402 \n",
            "R² Test: 0.8300816236036902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomForest"
      ],
      "metadata": {
        "id": "I_obxCyHSR-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення моделі RandomForestRegressor\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, max_features=0.8)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(random_forest_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVsiLAwUSRfq",
        "outputId": "904785c5-b7ae-49f2-861d-74573c83de28"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.17630416818019903 \n",
            "MSE Test: 0.2954913872801403\n",
            "MAE Train: 0.29678857644985635 \n",
            "MAE Test: 0.36622193754055243\n",
            "R² Train: 0.8681126258452431 \n",
            "R² Test: 0.7745044545735564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Після налаштування гіперпараметрів"
      ],
      "metadata": {
        "id": "eXSks839ps80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення моделі RandomForestRegressor\n",
        "random_forest_model = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=15, max_features=0.8, min_samples_split=10, min_samples_leaf=5)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(random_forest_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbvQZ4LASrFV",
        "outputId": "5096efe9-7088-4d14-b0e9-b6d184142913"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.12939315120801131 \n",
            "MSE Test: 0.2681250997016305\n",
            "MAE Train: 0.23231759576064917 \n",
            "MAE Test: 0.33808030645337744\n",
            "R² Train: 0.903205221279898 \n",
            "R² Test: 0.7953882305800719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catboost"
      ],
      "metadata": {
        "id": "FP4RdGkZViJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація моделі CatBoostRegressor\n",
        "catboost_model = CatBoostRegressor(iterations=1000, depth=6, learning_rate=0.1, loss_function='RMSE', verbose=100, random_seed=42)\n",
        "\n",
        "# Навчання моделі\n",
        "estimate(catboost_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558scVSaVhtj",
        "outputId": "45026647-1621-43f2-a3ad-8516fbf0d8e2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0934740\ttotal: 75.3ms\tremaining: 1m 15s\n",
            "100:\tlearn: 0.4867395\ttotal: 2.57s\tremaining: 22.9s\n",
            "200:\tlearn: 0.4320149\ttotal: 4.33s\tremaining: 17.2s\n",
            "300:\tlearn: 0.4020581\ttotal: 5.82s\tremaining: 13.5s\n",
            "400:\tlearn: 0.3803801\ttotal: 6.91s\tremaining: 10.3s\n",
            "500:\tlearn: 0.3633580\ttotal: 7.87s\tremaining: 7.83s\n",
            "600:\tlearn: 0.3488402\ttotal: 8.8s\tremaining: 5.84s\n",
            "700:\tlearn: 0.3358611\ttotal: 10.4s\tremaining: 4.45s\n",
            "800:\tlearn: 0.3234759\ttotal: 12.2s\tremaining: 3.03s\n",
            "900:\tlearn: 0.3126821\ttotal: 14s\tremaining: 1.54s\n",
            "999:\tlearn: 0.3025414\ttotal: 14.7s\tremaining: 0us\n",
            "MSE Train: 0.09153128427351812 \n",
            "MSE Test: 0.19244942923493022\n",
            "MAE Train: 0.21135212643198376 \n",
            "MAE Test: 0.28701788619115914\n",
            "R² Train: 0.9315284439361162 \n",
            "R² Test: 0.8531378886816883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking\n",
        "\n",
        "Стекінг (stacking) є методом ансамблювання в машинному навчанні, де прогнози декількох моделей (базових естиматорів) використовуються як вхідні дані для мета-моделі, яка робить кінцевий прогноз. Головна ідея стекінгу полягає в тому, щоб об'єднати сильні сторони різних моделей для покращення загальної продуктивності і точності прогнозування.\n",
        "\n",
        "### Етапи стекінгу:\n",
        "\n",
        "1. **Навчання базових моделей**: Спочатку набір базових моделей навчається на повному тренувальному наборі даних.\n",
        "\n",
        "2. **Генерація мета-ознак**: Кожна базова модель використовується для прогнозування на валідаційному наборі або через крос-валідацію на тренувальному наборі. Прогнози цих моделей стають вхідними даними (мета-ознаками) для наступного етапу.\n",
        "\n",
        "3. **Навчання мета-моделі**: Мета-модель (також звана моделлю другого рівня) навчається на мета-ознаках, тобто на прогнозах, згенерованих базовими моделями. Ціль мета-моделі — вивчити, як найкраще комбінувати прогнози базових моделей для вироблення точнішого кінцевого прогнозу."
      ],
      "metadata": {
        "id": "WipDMRXSUs8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначення базових моделей\n",
        "base_models = [\n",
        "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    LinearRegression()\n",
        "]\n",
        "\n",
        "# Навчання базових моделей і зберігання прогнозів як нових ознак\n",
        "X_train_meta = np.zeros((X_train.shape[0], len(base_models)))\n",
        "X_test_meta = np.zeros((X_test.shape[0], len(base_models)))\n",
        "\n",
        "for i, model in enumerate(base_models):\n",
        "    model.fit(X_train, y_train_raveled)\n",
        "    X_train_meta[:, i] = model.predict(X_train)\n",
        "    X_test_meta[:, i] = model.predict(X_test)\n",
        "\n",
        "# Навчання мета-моделі\n",
        "meta_model = LinearRegression()\n",
        "estimate(meta_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVAeM5OyTAG1",
        "outputId": "e9e9a0c9-6909-4893-b626-2b31d0372d8d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.5179331255246699 \n",
            "MSE Test: 0.5558915986952442\n",
            "MAE Train: 0.5286283596581934 \n",
            "MAE Test: 0.5332001304956565\n",
            "R² Train: 0.6125511913966952 \n",
            "R² Test: 0.575787706032451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('catboost', CatBoostRegressor(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_seed=42)),\n",
        "    ('extratrees', ExtraTreesRegressor(n_estimators=100, random_state=42)),\n",
        "    ('randomforest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('gradientboosting', GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "# Навчання стекінгу моделей\n",
        "estimate(stacking_model, X_train, X_test, y_train_raveled, y_test_raveled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnK7sYwrU1Qc",
        "outputId": "30d92554-9160-4cb0-82e0-6dce887d00cb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Train: 0.03858550095003229 \n",
            "MSE Test: 0.24175214651654348\n",
            "MAE Train: 0.13450533798587114 \n",
            "MAE Test: 0.31948581090996236\n",
            "R² Train: 0.9711354504361788 \n",
            "R² Test: 0.8155139727132571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Висновки\n",
        "\n",
        "Аналізуючи результати різних методів регресії, можна зробити наступні висновки:\n",
        "\n",
        "- **Класична модель дерева рішень (DecisionTreeRegressor)** показала високу точність на тренувальному наборі (R² = 1.0), але значно нижчу на тестовому (R² = 0.623), що свідчить про перенавчання моделі.\n",
        "\n",
        "- **Bagging на основі дерева рішень** показав помірну ефективність, але значне покращення після налаштування гіперпараметрів, з R² з 0.329 до 0.795 на тестовому наборі, що підкреслює важливість оптимізації моделі.\n",
        "\n",
        "- **Bagging на основі ExtraTreesRegressor** і **RandomForest** обидва показали дуже хороші результати, зокрема ExtraTreesRegressor вирізнявся високими показниками як на тренувальному, так і на тестовому наборах (R² = 0.964 та 0.830 відповідно).\n",
        "\n",
        "- **CatBoost** виявився найкращим з усіх індивідуальних моделей, демонструючи найвищу точність на тестовому наборі (R² = 0.853) і хорошу здатність до узагальнення.\n",
        "\n",
        "- Після налаштування гіперпараметрів, **RandomForest** родемонструвала поліпшення у всіх показниках. Це свідчить про те, що налаштування гіперпараметрів дозволило досягти кращого балансу між здатністю моделі навчатися на даних тренувального набору та її здатністю узагальнювати на даних тестового набору, покращуючи загальну ефективність.\n",
        "\n",
        "- **Stacking** з базовими моделями, що включають CatBoost, ExtraTreesRegressor, RandomForest і GradientBoostingRegressor, показав високу ефективність, особливо на тренувальному наборі (R² = 0.971), але меншу, хоча і все ще високу, на тестовому наборі (R² = 0.816).\n",
        "\n",
        "**Висновок**: Серед індивідуальних моделей **CatBoost** виявився найкращим за точністю та здатністю до узагальнення. Водночас, ансамбль використання **Stacking** з передовими моделями, включно з CatBoost, показав найкращі результати, демонструючи високу точність та здатність моделі адаптуватися до різних даних. Оптимізація гіперпараметрів є ключовою для покращення результатів, але вимагає обережності, щоб уникнути перенавчання або зниження загальної ефективності моделі.\n"
      ],
      "metadata": {
        "id": "AECle59GlFrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Класифікація"
      ],
      "metadata": {
        "id": "2VHZe4H_ju6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Зчитування даних\n",
        "data=pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "lrOYvRSzWc7u"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "WAcznSL5kO5s"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop('Unnamed: 32',axis=1)\n",
        "df=df.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "YOo-EZMTkKSi"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Поділ датасету на набір ознак X та набір міток цільової змінної y\n",
        "X0 = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']]\n",
        "y0 = df['diagnosis']"
      ],
      "metadata": {
        "id": "NZ_mjqGPkMpc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення категоріальних міток на числові\n",
        "label_encoder = LabelEncoder()\n",
        "y= label_encoder.fit_transform(y0)"
      ],
      "metadata": {
        "id": "23cIE9yKkSNt"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Стандартизція ознак\n",
        "scaler=StandardScaler()\n",
        "x=scaler.fit_transform(X0)"
      ],
      "metadata": {
        "id": "g0iYIDQvkT7q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(x)\n",
        "Y=np.array(y)"
      ],
      "metadata": {
        "id": "hSNXLiHDkcZw"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Поділ датасету на навчальну та тренувальну вибірки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EeqDLbwWkd7c"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Функція тренування та оцінки моделі класифікації"
      ],
      "metadata": {
        "id": "TZlaMNRHlO_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate(model, X_train, X_test, y_train, y_test):\n",
        "  # Навчання моделі\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Передбачення значень для тестового набору\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  # Оцінка моделі\n",
        "  acc_test = accuracy_score(y_test, y_test_pred)\n",
        "  acc_train = accuracy_score(y_train, y_train_pred)\n",
        "  recall_test = recall_score(y_test, y_test_pred)\n",
        "  recall_train = recall_score(y_train, y_train_pred)\n",
        "  precision_test = precision_score(y_test, y_test_pred)\n",
        "  precision_train = precision_score(y_train, y_train_pred)\n",
        "  f1_test = f1_score(y_test, y_test_pred)\n",
        "  f1_train = f1_score(y_train, y_train_pred)\n",
        "  roc_auc = roc_auc_score(y_test, dt.predict_proba(X_test)[:, 1])\n",
        "\n",
        "  # Виведення результатів\n",
        "  print(\"Accuracy Train:\", acc_train, \"\\nAccuracy Test:\", acc_test)\n",
        "  print(\"Recall Train:\", recall_train, \"\\nRecall Test:\", recall_test)\n",
        "  print(\"Precision Train:\", precision_train, \"\\nPrecision Test:\", precision_test)\n",
        "  print(\"F1 Train:\", f1_train, \"\\nF1 Test:\", f1_test)\n",
        "  print(\"ROC AUC Test:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "0iUlvZ3NlSHo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Класична модель дерева рішень DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "FE4LSMWjkupU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення та тренування моделі дерева рішень\n",
        "dt = DecisionTreeClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "GQmxLEB8mjVl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate(dt, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBUZbYIummEU",
        "outputId": "75fdc99e-dfb0-40d2-e5fe-1c73bf6fc830"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 1.0 \n",
            "Accuracy Test: 0.9298245614035088\n",
            "Recall Train: 1.0 \n",
            "Recall Test: 0.9302325581395349\n",
            "Precision Train: 1.0 \n",
            "Precision Test: 0.8888888888888888\n",
            "F1 Train: 1.0 \n",
            "F1 Test: 0.9090909090909092\n",
            "ROC AUC Test: 0.9299050114641335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Після налаштування гіперпараметрів"
      ],
      "metadata": {
        "id": "_vTZJ7mQpp2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення та тренування моделі дерева рішень\n",
        "dt = DecisionTreeClassifier(random_state=42, criterion='gini', min_samples_leaf=4, min_samples_split=2)"
      ],
      "metadata": {
        "id": "HyXXFlZJkhIj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate(dt, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXrHn64gk4Ab",
        "outputId": "09b2ada0-0c54-4bbf-d4fd-6c2b27bf4825"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 0.967032967032967 \n",
            "Accuracy Test: 0.9385964912280702\n",
            "Recall Train: 0.9112426035502958 \n",
            "Recall Test: 0.8604651162790697\n",
            "Precision Train: 1.0 \n",
            "Precision Test: 0.9736842105263158\n",
            "F1 Train: 0.9535603715170279 \n",
            "F1 Test: 0.9135802469135803\n",
            "ROC AUC Test: 0.9534883720930232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging на основі моделі дерева рішень"
      ],
      "metadata": {
        "id": "Jg6KGiXnmtth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення базової моделі дерева рішень\n",
        "dt = DecisionTreeClassifier(random_state=42, criterion='gini', min_samples_leaf=4, min_samples_split=2)\n",
        "dt.fit(X_test, y_test)\n",
        "\n",
        "# Створення моделі бегінгу з дерева рішень як базової моделі\n",
        "bagging_model = BaggingClassifier(estimator=dt, n_estimators=200, random_state=42)\n",
        "\n",
        "# Оцінка моделі\n",
        "estimate(bagging_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXDARuzWmtbD",
        "outputId": "61e88255-8184-40db-cada-36b0b7cdbd7c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 0.9692307692307692 \n",
            "Accuracy Test: 0.9473684210526315\n",
            "Recall Train: 0.9526627218934911 \n",
            "Recall Test: 0.9302325581395349\n",
            "Precision Train: 0.9640718562874252 \n",
            "Precision Test: 0.9302325581395349\n",
            "F1 Train: 0.9583333333333333 \n",
            "F1 Test: 0.9302325581395349\n",
            "ROC AUC Test: 0.9995086799868982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Після налаштування гіперпараметрів"
      ],
      "metadata": {
        "id": "ep790LzZpiJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація моделі бегінгу з деревом рішень як базовим естиматором\n",
        "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42, criterion='gini', min_samples_leaf=4, min_samples_split=2),\n",
        "                                  random_state=42, bootstrap = False, bootstrap_features=False, max_features=1.0, max_samples=0.75, n_estimators=50)\n",
        "\n",
        "# Оцінка моделі\n",
        "estimate(bagging_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYnOjU-hpA3B",
        "outputId": "8b98e0d9-2ba3-4617-b7a6-3730d266a3f2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 0.9824175824175824 \n",
            "Accuracy Test: 0.9649122807017544\n",
            "Recall Train: 0.9644970414201184 \n",
            "Recall Test: 0.9534883720930233\n",
            "Precision Train: 0.9878787878787879 \n",
            "Precision Test: 0.9534883720930233\n",
            "F1 Train: 0.9760479041916168 \n",
            "F1 Test: 0.9534883720930233\n",
            "ROC AUC Test: 0.9995086799868982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient boosting"
      ],
      "metadata": {
        "id": "TOmlZ0Tkpyj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація моделі градієнтного бустингу\n",
        "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Оцінка моделі\n",
        "estimate(gb, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqaxsi_Zoife",
        "outputId": "3c11646a-4e18-4177-c82e-552536f0b474"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 1.0 \n",
            "Accuracy Test: 0.956140350877193\n",
            "Recall Train: 1.0 \n",
            "Recall Test: 0.9302325581395349\n",
            "Precision Train: 1.0 \n",
            "Precision Test: 0.9523809523809523\n",
            "F1 Train: 1.0 \n",
            "F1 Test: 0.9411764705882352\n",
            "ROC AUC Test: 0.9995086799868982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n"
      ],
      "metadata": {
        "id": "pZO7WzDtqK_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення датасету для LightGBM\n",
        "train_data = lgb.Dataset(X_train, label=y_train, params={'verbose': -1}, free_raw_data=False)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, params={'verbose': -1}, free_raw_data=False)\n",
        "\n",
        "# Встановлення параметрів\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Навчання моделі\n",
        "gbm = lgb.train(params,\n",
        "                train_data,\n",
        "                num_boost_round=300,\n",
        "                valid_sets=[train_data, test_data],\n",
        "                valid_names=['train', 'eval'])\n",
        "\n",
        "# Передбачення\n",
        "y_pred_test = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_pred_train = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
        "y_pred_binary_test = [1 if x > 0.5 else 0 for x in y_pred_test]\n",
        "y_pred_binary_train = [1 if x > 0.5 else 0 for x in y_pred_train]"
      ],
      "metadata": {
        "id": "oXu6arRRp-x-"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Оцінка моделі\n",
        "  acc_test = accuracy_score(y_test, y_pred_binary_test)\n",
        "  acc_train = accuracy_score(y_train, y_pred_binary_train)\n",
        "  recall_test = recall_score(y_test, y_pred_binary_test)\n",
        "  recall_train = recall_score(y_train, y_pred_binary_train)\n",
        "  precision_test = precision_score(y_test, y_pred_binary_test)\n",
        "  precision_train = precision_score(y_train, y_pred_binary_train)\n",
        "  f1_test = f1_score(y_test, y_pred_binary_test)\n",
        "  f1_train = f1_score(y_train, y_pred_binary_train)\n",
        "  roc_auc = roc_auc_score(y_test, y_pred_binary_test)\n",
        "\n",
        "  # Виведення результатів\n",
        "  print(\"Accuracy Train:\", acc_train, \"\\nAccuracy Test:\", acc_test)\n",
        "  print(\"Recall Train:\", recall_train, \"\\nRecall Test:\", recall_test)\n",
        "  print(\"Precision Train:\", precision_train, \"\\nPrecision Test:\", precision_test)\n",
        "  print(\"F1 Train:\", f1_train, \"\\nF1 Test:\", f1_test)\n",
        "  print(\"ROC AUC Test:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX6MquPrsp_m",
        "outputId": "a29cd22c-26d6-4ba9-d444-7d3ec4d1efda"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 1.0 \n",
            "Accuracy Test: 0.9736842105263158\n",
            "Recall Train: 1.0 \n",
            "Recall Test: 0.9534883720930233\n",
            "Precision Train: 1.0 \n",
            "Precision Test: 0.9761904761904762\n",
            "F1 Train: 1.0 \n",
            "F1 Test: 0.9647058823529412\n",
            "ROC AUC Test: 0.9697019325253848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking\n"
      ],
      "metadata": {
        "id": "7Q4qo0Idth5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('lr', LogisticRegression(random_state=42))\n",
        "]\n",
        "\n",
        "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "# Оцінка моделі\n",
        "estimate(stacking_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h2YxOjitZYq",
        "outputId": "9f4868bf-2e65-42f3-be2a-58519aedaa65"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 0.9340659340659341 \n",
            "Accuracy Test: 0.9473684210526315\n",
            "Recall Train: 0.8875739644970414 \n",
            "Recall Test: 0.9302325581395349\n",
            "Precision Train: 0.9316770186335404 \n",
            "Precision Test: 0.9302325581395349\n",
            "F1 Train: 0.9090909090909092 \n",
            "F1 Test: 0.9302325581395349\n",
            "ROC AUC Test: 0.9995086799868982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42, criterion='gini', min_samples_leaf=4, min_samples_split=2)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
        "    ('lr', LogisticRegression(random_state=42))\n",
        "]\n",
        "\n",
        "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "# Оцінка моделі\n",
        "estimate(stacking_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q9bg0BduH_8",
        "outputId": "1c01a4f3-cb8e-4174-a72a-460c86b7c2dd"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train: 0.9604395604395605 \n",
            "Accuracy Test: 0.956140350877193\n",
            "Recall Train: 0.893491124260355 \n",
            "Recall Test: 0.9534883720930233\n",
            "Precision Train: 1.0 \n",
            "Precision Test: 0.9318181818181818\n",
            "F1 Train: 0.9437500000000001 \n",
            "F1 Test: 0.942528735632184\n",
            "ROC AUC Test: 0.9995086799868982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Висновки\n",
        "\n",
        "Аналізуючи результати застосування різних методів класифікації та їх зміни після налаштування гіперпараметрів, можна зробити наступні висновки:\n",
        "\n",
        "1. **DecisionTreeClassifier**: Початкові результати показали високу точність на тренувальному наборі даних і досить хорошу на тестовому. Після налаштування гіперпараметрів, точність на тренувальному наборі знизилася, але точність на тестовому наборі злегка покращилася, свідчачи про зменшення перенавчання і кращу здатність узагальнення.\n",
        "\n",
        "2. **Bagging (на основі DecisionTreeClassifier)**: Показав високу ефективність як до, так і після налаштування гіперпараметрів, з значним покращенням показників після налаштування. Це демонструє, що використання ансамблів може ефективно зменшувати варіативність і покращувати точність прогнозування.\n",
        "\n",
        "3. **Gradient Boosting**: Продемонстрував високі показники на тренувальному наборі та дуже хорошу точність на тестовому наборі, підтверджуючи ефективність градієнтного бустингу для задач класифікації.\n",
        "\n",
        "4. **LightGBM**: Виявився найкращим серед окремих моделей, показавши виняткові результати на тестовому наборі. Це підкреслює перевагу використання легких градієнтних бустингових моделей для задач з великими даними.\n",
        "\n",
        "5. **Stacking**: Початковий stacking показав хороші результати, але після оптимізації базових моделей і включення мета-моделі (RandomForest) якості класифікації було значно покращено. Це підкреслює значення вибору правильного набору базових моделей та мета-моделі у стекінгу для досягнення високої точності прогнозування.\n",
        "\n",
        "**Загальний висновок**: Кожен метод класифікації має свої переваги та недоліки, а налаштування гіперпараметрів грає ключову роль у покращенні точності та здатності до узагальнення моделей. Ансамблеві методи, такі як bagging і stacking, разом із градієнтним бустингом, зокрема LightGBM, демонструють високу ефективність у задачах класифікації, покращуючи стійкість до перенавчання та підвищуючи загальну точність моделі."
      ],
      "metadata": {
        "id": "wvVybN9QmnJ-"
      }
    }
  ]
}